\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{verbatim} % to comment out blocks
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{placeins}


\begin{document}
\title{Writing Scientific Papers and Software}

\author{
  Capucine Berger-Sigrist, Mihai David, Tiberiu Mosnoi\\
  \textit{Department of Computer Science, EPFL, Switzerland}
}

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}
    \item State the problem.
    \item Say why it is an interesting problem.
    \item Say what your solution achieves.
    \item Say what follows from your solution.
\end{enumerate}

%% draft of abstract, open for change :)
In this project, we explored how different regression methods could 
be implemented to predict the outcome of simulated events from the ATLAS 
experiment. Most notably, we are interested in classifying the signal 
originating from the decay of particles during proton-proton collisions, 
as either the decay of a Higgs boson or background noise.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Describe your problem and state your
%%contributions. The hope is that after reading your
%%paper, the audience will be convinced to try out your idea.

%%At that point, it is important that the reader is able to reproduce your
%%work~\cite{schwab00,wavelab,gentleman05}. This is why it is also
%%important that if the work has a computational component, the software
%%associated with producing the results are also made available in a
%%useful form. Several guidelines for making your user's experience with
%%your software as painless as possible is given in
%%Section~\ref{sec:tips-software}.

The ATLAS and CMS experiments were able to confirm the existence of 
the Higgs boson by analysing the decay of particles produced by 
the collision of protons in the CERN's LHC. 
As such, using a combination of regression and data preprocessing 
methods, the aim of this project is to predict whether the observed 
signals come from the decay of a Higgs boson or from background noise.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Models and Methods}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%The models and methods section should describe what was
%%done to answer the research question, describe how it was done,
%%justify the experimental design, and explain how the results were analyzed.

%%The model refers to the underlying mathematical model or structure which 
%%you use to describe your problem, or that your solution is based on. 
%%The methods on the other hand, are the algorithms used to solve the problem. 
%%In some cases, the suggested method directly solves the problem, without having it 
%%stated in terms of an underlying model. Generally though it is a better practice to have 
%%the model figured out and stated clearly, rather than presenting a method without specifying 
%%the model. In this case, the method can be more easily evaluated in the task of fitting 
%%the given data to the underlying model.

%%The methods part of this section, detailed enough such
%%that an interested reader can reproduce your
%%work~\cite{anderson04,wavelab}.

%%clear and precise description of how an experiment was done, and the rationale
%%for why specific experimental procedures were chosen. It is usually helpful to
%%structure the methods section by~\cite{kallet04methods}:
%%\begin{enumerate}
%%\item Layout the model you used to describe the problem or the solution.
%%\item Describing the algorithms used in the study, briefly including
%%  details such as hyperparameter values (e.g. thresholds), and
%%  preprocessing steps (e.g. normalizing the data to have mean value of
%%  zero).
%%\item Explaining how the materials were prepared, for example the
%%  images used and their resolution.
%%\item Describing the research protocol, for example which examples
%%  were used for estimating the parameters (training) and which were
%%  used for computing performance.
%%\item Explaining how measurements were made and what
%%  calculations were performed. Do not reproduce the full source code in
%%  the paper, but explain the key steps.
%%\end{enumerate}

We used a linear regression model on the train set to effectively 
predict the outputs for the data of the test set. For this we implemented 
different methods, one of them being least squares and then optimized the 
loss using gradient or stochastic gradient descent.
Our second method relied on ridge regression to penalise large weights 
vectors and avoid potentially over or underfitting the model.
Finally the last solution we explored was logistic and regularized 
logistic regression. During this project we chose to focus our attention on
the last two methods.

\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lrrrrrr@{}}
\toprule
 &
  \multicolumn{1}{c}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l}{Training} &
  \multicolumn{1}{l}{Validation} &
  \multicolumn{1}{l}{Testing} \\ \midrule
 &
  \multicolumn{3}{c}{Parameters} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{F1-score} \\ \midrule
Methods &
  \multicolumn{1}{l}{Gamma} &
  \multicolumn{1}{l}{Lambda} &
  \multicolumn{1}{l}{Max\_iters} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{Accuracy} \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Regularized logistic \\ regression\end{tabular}} &
  0.4 &
  5e-2 &
  6000 &
  44.79\% &
  44.80\% &
  44.90\% \\
 &
   &
   &
   &
  72.80\% &
  72.80\% &
  72.90\% \\
\multirow{2}{*}{Ridge Regression} &
  - &
  1e-4 &
  - &
  56.70\% &
  56.70\% &
  56.70\% \\
 &
   &
   &
   &
  74.43\% &
  74.42\% &
  74.40\% \\ \bottomrule
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results for the initial implementation
using the entire data-set.}
\label{tab:baseline}
\end{table}

\begin{comment}
\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lrrr|r|r|r|}
\cline{5-7}
 &
  \multicolumn{1}{c}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{Training} &
  \multicolumn{1}{l|}{Validation} &
  \multicolumn{1}{l|}{Testing} \\ \cline{2-7} 
\multicolumn{1}{l|}{} &
  \multicolumn{3}{c|}{Parameters} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{F1-score} \\ \hline
\multicolumn{1}{|l|}{Methods} &
  \multicolumn{1}{l|}{Gamma} &
  \multicolumn{1}{l|}{Lambda} &
  \multicolumn{1}{l|}{Max\_iters} &
  \multicolumn{1}{l|}{Accuracy} &
  \multicolumn{1}{l|}{Accuracy} &
  \multicolumn{1}{l|}{Accuracy} \\ \hline
\multicolumn{1}{|l|}{\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Regularized logistic \\ regression\end{tabular}}} &
  \multicolumn{1}{r|}{0.4} &
  \multicolumn{1}{r|}{5e-2} &
  6000 &
  44.79\% &
  44.80\% &
  44.90\% \\
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{r|}{} &
  \multicolumn{1}{r|}{} &
   &
  72.80\% &
  72.80\% &
  72.90\% \\ \hline
\multicolumn{1}{|l|}{\multirow{2}{*}{Ridge Regression}} &
  \multicolumn{1}{r|}{-} &
  \multicolumn{1}{r|}{1e-4} &
  - &
  56.70\% &
  56.70\% &
  56.70\% \\
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{r|}{} &
  \multicolumn{1}{r|}{} &
   &
  74.43\% &
  74.42\% &
  74.40\% \\ \hline
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results for the initial implementation
using the entire data-set.}
\label{tab:baseline}
\end{table}
\end{comment}

As Table~\ref{tab:baseline} shows, with only standardization applied to 
the data-set and a regularization threshold of 0.5, ridge regression has 
a slight edge both in terms of F1-score and accuracy over regularized 
logistic regression.
But we can also see that, as is, these models are not optimal, and while 
they are useful baselines, they could be improved by analysing and 
preprocessing the data-set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Hyperparameters}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% this subsection could also go just before the intermediate results but then
%% the structure of the paper would be almost identical to the other paper...
To tune the hyperparameters we first devised a grid search method to compute \textit{(lambda, degree)} pairs using cross-validation and keeping the 
configuration that maximised the F1-score. With this first result we then obtained
the optimal regularization threshold.

%%Unfortunately, this proved too computationally expensive. Therefore, 
%%we had to go for a trial and error methodology to pinpoint the most 
%%accurately the optimal parameters.
%%Still, even by tuning the parameters to the best of our abilities, 
%%we realised that to improve on our results we needed to analyse more 
%%carefully the data-set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data preprocessing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The data set comes from the simulation of 250.000 simulated events 
of proton-proton collisions. Each data is composed of 30 features 
that can be divided into two categories: primitive features related 
to the momenta of particles or derived feature obtained from the former.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Feature distribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Our first step in the data preprocessing was to standardize the features 
to ensure internal consistency. Data points were considered to be 
outliers if they were at +/- 3 standard deviation from their mean and 
were, as such, removed. We later observed that most of the features 
were right skewed. As such, using the log transform should have enabled 
us to have a more balanced distribution, but after multiple experiments, 
we realised that it did not improve our predictions. 
Finally, undefined features represented by the value -999.0 or Nan, 
were replaced either by their mean, median or mode. Overall, the 
latter two tended to yield a better accuracy and F1-score.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Feature expansion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
By augmenting the feature vectors we found that we could obtain a more 
powerful model. One way was to do that was to use polynomial expansion 
by carefully choosing a degree d:
$$\phi := [1, X, X^2, ..., X^d]$$
where $X$ represents the features matrix and then fitting our model 
to the new matrix $\phi$. Atop of this, we increased the complexity 
of the model by multiplying each feature together:
$$\forall \phi_{:i} \neq \phi_{:j}, \;\; \phi := [\phi\; |\; \phi_{:i} * \phi_{:j}] $$
And then we applied the square root to the positive feature columns 
of $\phi$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Intermediate results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%********************************
missing transition
%%********************************
Since our baseline did not suffer from overfitting while training them on the entire
data-set, we decided to switch to logistic regression instead of regularized.

cross val k = 5 ?
Log: deg 3, square root, replace with median, remove outliers 'std', reg\_thres = 0.05
ridge: 15 deg, square root, replace with mode, don't remove outliers, reg\_thres = 0.5

\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lrrrrrr@{}}
\toprule
 &
  \multicolumn{1}{c}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l}{Training} &
  \multicolumn{1}{l}{Validation} &
  \multicolumn{1}{l}{Testing} \\ \midrule
 &
  \multicolumn{3}{c}{Parameters} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{F1-score} \\ \midrule
Methods &
  \multicolumn{1}{l}{Gamma} &
  \multicolumn{1}{l}{Lambda} &
  \multicolumn{1}{l}{Max\_iters} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{Accuracy} \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Logistic \\ regression\end{tabular}} &
  0.5 &
  - &
  10000 &
  71.20\% &
  71.43\% &
  71.20\% \\
 &
   &
   &
   &
  80.10\% &
  81.66\% &
  80.80\% \\
\multirow{2}{*}{Ridge Regression} &
  - &
  1e-4 &
  - &
  72.97\% &
  72.70\% &
  73.40\% \\
 &
   &
   &
   &
  82.22\% &
  82.00\% &
  80.30\% \\ \bottomrule
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results after preprocessing the data.}
\label{tab:intermediate}
\end{table}

\begin{comment}
\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lrrr|r|r|r|}
\cline{5-7}
 &
  \multicolumn{1}{c}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{Training} &
  \multicolumn{1}{l|}{Validation} &
  \multicolumn{1}{l|}{Testing} \\ \cline{2-7} 
\multicolumn{1}{l|}{} &
  \multicolumn{3}{c|}{Parameters} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{F1-score} \\ \hline
\multicolumn{1}{|l|}{Methods} &
  \multicolumn{1}{l|}{Gamma} &
  \multicolumn{1}{l|}{Lambda} &
  \multicolumn{1}{l|}{Max\_iters} &
  \multicolumn{1}{l|}{Accuracy} &
  \multicolumn{1}{l|}{Accuracy} &
  \multicolumn{1}{l|}{Accuracy} \\ \hline
\multicolumn{1}{|l|}{\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Logistic \\ regression\end{tabular}}} &
  \multicolumn{1}{r|}{0.5} &
  \multicolumn{1}{r|}{-} &
  10000 &
  71.20\% &
  71.43\% &
  71.20\% \\
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{r|}{} &
  \multicolumn{1}{r|}{} &
   &
  80.10\% &
  81.66\% &
  80.80\% \\ \hline
\multicolumn{1}{|l|}{\multirow{2}{*}{Ridge Regression}} &
  \multicolumn{1}{r|}{-} &
  \multicolumn{1}{r|}{1e-4} &
  - &
  72.97\% &
  72.70\% &
  73.40\% \\
\multicolumn{1}{|l|}{} &
  \multicolumn{1}{r|}{} &
  \multicolumn{1}{r|}{} &
   &
  82.22\% &
  82.00\% &
  80.30\% \\ \hline
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results after preprocessing the data.}
\label{tab:intermediate}
\end{table}
\end{comment}

\FloatBarrier
We expected that logistic regression would fare better, seeing as it uses 
the sigmoid function and is, therefore, less liable to be influenced by extreme 
range of values, as is the case in the data-set. 
But as Table~\ref{tab:intermediate} shows, ridge regression has a comparable
accuracy but overall a better F1-score. Which is why, to simplify our 
experiments, we kept ridge regression for our model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Further data analysis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The description of the feature in the Learning to discover: the Higgs
boson machine learning challenge~\cite{higgsMLdoc} documentation pointed 
to the fact that a lot of features depend on the value (either 0, 1, 2 or 3)
of the \textit{PRI\_jet\_num} feature.

Inspecting the data, we saw that some features (up to eleven out of the thirty) 
were marked as undefined for data points with a \textit{PRI\_jet\_num} of 0 or 1, 
which is not the case for 2 or 3. Consequently, we decided to split the 
original data-set into three subsets according to their \textit{PRI\_jet\_num} value: 
\begin{enumerate}
    \item \textit{PRI\_jet\_0} with N = 99913
    \item \textit{PRI\_jet\_1} with N=77544
    \item \textit{PRI\_jet\_2\_3} with N=72543
\end{enumerate}
\textit{PRI\_jet\_num} 2 and 3 where grouped together to have more 
balanced subsets.
%%********************************
rewrite text
%%********************************
all subsets still had undefined values (-999) for the first feature \textit{DER\_mass\_MMC} split again each subset
depending on whether or not the feature is defined.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
From Table~\ref{tab:intermediate} we saw that, overall, ridge regression
performed better and had the advantage of being computationally faster.
As such, we chose to focus our attention on this model. For each subset we
tuned the parameters accordingly and preprocessed the feature matrix 
following the aforementioned methods: 
%%********************************
rewrite text
subset 0: multiply each, square root, don't remove outliers
subset 1: multiply each, square root, don't remove outliers
subset 2: multiply each, square root, don't remove outliers
%%********************************
We used a 10-fold cross-validation to estimate the generalized error or the 
model and its variance.

\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lrrrrrrrrr@{}}
\toprule
               & \multicolumn{3}{c}{Parameters} & \multicolumn{2}{c}{Training} & \multicolumn{2}{c}{Validation} & \multicolumn{2}{c}{Testing} \\ \midrule
Subsets &
  \multicolumn{1}{l}{Lambda} &
  \multicolumn{1}{l}{Degree} &
  \multicolumn{1}{l}{Replace with} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} \\ \midrule
PRI\_jet\_0 &
  1e-15 &
  10 &
  median &
  \multirow{3}{*}{74.29\%} &
  \multirow{3}{*}{83.59\%} &
  \multirow{3}{*}{73.97\%} &
  \multirow{3}{*}{83.26\%} &
  \multirow{3}{*}{75.10\%} &
  \multirow{3}{*}{83.40\%} \\
PRI\_jet\_1    & 1e-13      & 11     & mode     &               &              &                &               &              &              \\
PRI\_jet\_2\_3 & 1e-16      & 11     & mode     &               &              &                &               &              &              \\ \bottomrule
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results.}
\label{tab:3_models}
\end{table}

\begin{comment}
\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lrrrrrrrrr@{}}
\toprule
 &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{6}{c}{Overall} \\ \midrule
 &
  \multicolumn{3}{c}{Parameters} &
  \multicolumn{2}{c}{Training} &
  \multicolumn{2}{c}{Validation} &
  \multicolumn{2}{c}{Testing} \\ \midrule
Subsets &
  \multicolumn{1}{l}{Lambda} &
  \multicolumn{1}{l}{Degree} &
  \multicolumn{1}{l}{Replace with} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} \\ \midrule
PRI\_jet\_0 &
  1e-15 &
  10 &
  median &
  \multirow{3}{*}{74.29\%} &
  \multirow{3}{*}{83.59\%} &
  \multirow{3}{*}{73.97\%} &
  \multirow{3}{*}{83.26\%} &
  \multirow{3}{*}{75.10\%} &
  \multirow{3}{*}{83.40\%} \\
PRI\_jet\_1 &
  1e-13 &
  11 &
  mode &
   &
   &
   &
   &
   &
   \\
PRI\_jet\_2\_3 &
  1e-16 &
  11 &
  mode &
   &
   &
   &
   &
   &
   \\ \bottomrule
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results.}
\label{tab:3_models}
\end{table}
\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|}
\cline{2-10}
                                     & \multicolumn{3}{c|}{Parameters} & \multicolumn{2}{c|}{Training} & \multicolumn{2}{c|}{Validation} & \multicolumn{2}{c|}{Testing} \\ \hline
\multicolumn{1}{|l|}{Subsets} &
  \multicolumn{1}{l|}{Lambda} &
  \multicolumn{1}{l|}{Degree} &
  \multicolumn{1}{l|}{Replace with} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{Accuracy} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{Accuracy} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{Accuracy} \\ \hline
\multicolumn{1}{|l|}{PRI\_jet\_0} &
  1e-15 &
  10 &
  median &
  \multirow{3}{*}{74.29\%} &
  \multirow{3}{*}{83.59\%} &
  \multirow{3}{*}{73.97\%} &
  \multirow{3}{*}{83.26\%} &
  \multirow{3}{*}{75.10\%} &
  \multirow{3}{*}{83.40\%} \\ \cline{1-4}
\multicolumn{1}{|l|}{PRI\_jet\_1}    & 1e-13      & 11      & mode     &               &               &                &                &               &              \\ \cline{1-4}
\multicolumn{1}{|l|}{PRI\_jet\_2\_3} & 1e-16      & 11      & mode     &               &               &                &                &               &              \\ \hline
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results.}
\label{tab:3_models}
\end{table}
\end{comment}

%%********************************
missing transition
%%********************************

\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lrrrrrrrrr@{}}
\toprule
                  & \multicolumn{3}{c}{Parameters} & \multicolumn{2}{c}{Training} & \multicolumn{2}{c}{Validation} & \multicolumn{2}{c}{Testing} \\ \midrule
Subsets &
  \multicolumn{1}{l}{Lambda} &
  \multicolumn{1}{l}{Degree} &
  \multicolumn{1}{l}{Replace with} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} \\ \midrule
PRI\_jet\_0\_0 &
  1e-8 &
  10 &
  median &
  \multirow{6}{*}{61.66\%} &
  \multirow{6}{*}{87.76\%} &
  \multirow{6}{*}{59.05\%} &
  \multirow{6}{*}{87.20\%} &
  \multirow{6}{*}{75.30\%} &
  \multirow{6}{*}{83.50\%} \\
PRI\_jet\_0\_1    & 1e-14     & 10     & median    &               &              &                &               &              &              \\
PRI\_jet\_1\_0    & 1e-8      & 6      & mode      &               &              &                &               &              &              \\
PRI\_jet\_1\_1    & 1e-16     & 10     & mode      &               &              &                &               &              &              \\
PRI\_jet\_2\_3\_0 & 1e-3      & 3      & mode      &               &              &                &               &              &              \\
PRI\_jet\_2\_3\_1 & 1e-15     & 11     & mode      &               &              &                &               &              &              \\ \bottomrule
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results.}
\label{tab:6_models}
\end{table}

\begin{comment}
\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lrrrrrrrrr@{}}
\toprule
 &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{1}{l}{} &
  \multicolumn{6}{c}{Overall} \\ \midrule
 &
  \multicolumn{3}{c}{Parameters} &
  \multicolumn{2}{c}{Training} &
  \multicolumn{2}{c}{Validation} &
  \multicolumn{2}{c}{Testing} \\ \midrule
Subsets &
  \multicolumn{1}{l}{Lambda} &
  \multicolumn{1}{l}{Degree} &
  \multicolumn{1}{l}{Replace with} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} &
  \multicolumn{1}{l}{F1-score} &
  \multicolumn{1}{l}{Accuracy} \\ \midrule
PRI\_jet\_0\_0 &
  1e-8 &
  10 &
  median &
  \multirow{6}{*}{61.66\%} &
  \multirow{6}{*}{87.76\%} &
  \multirow{6}{*}{59.05\%} &
  \multirow{6}{*}{87.20\%} &
  \multirow{6}{*}{75.30\%} &
  \multirow{6}{*}{83.50\%} \\
PRI\_jet\_0\_1 &
  1e-14 &
  10 &
  median &
   &
   &
   &
   &
   &
   \\
PRI\_jet\_1\_0 &
  1e-8 &
  6 &
  mode &
   &
   &
   &
   &
   &
   \\
PRI\_jet\_1\_1 &
  1e-16 &
  10 &
  mode &
   &
   &
   &
   &
   &
   \\
PRI\_jet\_2\_3\_0 &
  1e-3 &
  3 &
  mode &
   &
   &
   &
   &
   &
   \\
PRI\_jet\_2\_3\_1 &
  1e-15 &
  11 &
  mode &
   &
   &
   &
   &
   &
   \\ \bottomrule
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results.}
\label{tab:6_models}
\end{table}
\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|}
\cline{2-10}
                                        & \multicolumn{3}{c|}{Parameters} & \multicolumn{2}{c|}{Training} & \multicolumn{2}{c|}{Validation} & \multicolumn{2}{c|}{Testing} \\ \hline
\multicolumn{1}{|l|}{Subsets} &
  \multicolumn{1}{l|}{Lambda} &
  \multicolumn{1}{l|}{Degree} &
  \multicolumn{1}{l|}{Replace with} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{Accuracy} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{Accuracy} &
  \multicolumn{1}{l|}{F1-score} &
  \multicolumn{1}{l|}{Accuracy} \\ \hline
\multicolumn{1}{|l|}{PRI\_jet\_0\_0} &
  1e-8 &
  10 &
  median &
  \multirow{6}{*}{61.66\%} &
  \multirow{6}{*}{87.76\%} &
  \multirow{6}{*}{59.05\%} &
  \multirow{6}{*}{87.20\%} &
  \multirow{6}{*}{75.30\%} &
  \multirow{6}{*}{83.50\%} \\ \cline{1-4}
\multicolumn{1}{|l|}{PRI\_jet\_0\_1}    & 1e-14     & 10     & median     &               &               &                &                &               &              \\ \cline{1-4}
\multicolumn{1}{|l|}{PRI\_jet\_1\_0}    & 1e-8      & 6      & mode       &               &               &                &                &               &              \\ \cline{1-4}
\multicolumn{1}{|l|}{PRI\_jet\_1\_1}    & 1e-16     & 10     & mode       &               &               &                &                &               &              \\ \cline{1-4}
\multicolumn{1}{|l|}{PRI\_jet\_2\_3\_0} & 1e-3      & 3      & mode       &               &               &                &                &               &              \\ \cline{1-4}
\multicolumn{1}{|l|}{PRI\_jet\_2\_3\_1} & 1e-15     & 11     & mode       &               &               &                &                &               &              \\ \hline
\end{tabular}%
}
\caption{Parameters, F1-score and accuracy results.}
\label{tab:6_models}
\end{table}
\end{comment}

\FloatBarrier
Grid search for (lambda, degree)
%%********************************
missing transition
%%********************************
%%When reporting computational or measurement results, always
%%report the mean (average value) along with a measure of variability
%%(standard deviation(s) or standard error of the mean).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Discuss the strengths and weaknesses of your approach, 
%%based on the results. Point out the implications of your novel idea on the application concerned.

%% Discussion ideas
Test results from AIcrowd accuracy 0.833 f1-score 0.749	
And try to understand why log transform does not help. tested trigonometric 
for values with angles in radian but did not help, neither did dropping correlated features.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%Summarize your contributions in light of the new results.

%%The aim of a scientific paper is to convey the idea or discovery of
%%the researcher to the minds of the readers. The associated software
%%%%package provides the relevant details, which are often only briefly
%%explained in the paper, such that the research can be reproduced.
%%To write good papers, identify your key idea, make your contributions
%%explicit, and use examples and illustrations to describe the problems
%%and solutions.
Data pre-processing was an integral part. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The author thanks Christian Sigg for his careful reading and helpful
suggestions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\section{The Structure of a Paper}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\label{sec:structure-paper}
%%Scientific papers usually begin with the description of the problem,
%%justifying why the problem is interesting. Most importantly, it argues
%%that the problem is still unsolved, or that the current solutions are
%%unsatisfactory. This leads to the main gist of the paper, which is
%%``the idea''. The authors then show evidence, using derivations or
%%experiments, that the idea works. Since science does not occur in a
%%vacuum, a proper comparison to the current state of the art is often
%%part of the results.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
\bibliography{CTM-literature}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
