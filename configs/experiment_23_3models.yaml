# Parameters for each of the models (by jet number)

# Best results

# Cross validation f1 score is 65.24 % and accuracy is 84.11 %
# Training F1 score is 65.35 % and accuracy is 84.15 % 

# Cross validation f1 score is 71.92 % and accuracy is 80.56 %
# Training F1 score is 72.04 % and accuracy is 80.66 % 

# Cross validation f1 score is 81.46 % and accuracy is 83.29 %
# Training F1 score is 81.69 % and accuracy is 83.50 % 

# Overall validation F1 score is 72.88 % and accuracy is 82.65 %
# Overall test F1 score is 74 % and accuracy is 82.9 %

zero_jet:
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter
  lambda: 0
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 6
  # Whether to multiply each column with each column and expand features
  multiply_each: False
  # Take square root of features
  square_root: True
  # Apply log transform as scalar
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'median'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: False
  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"

one_jet:
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter
  lambda: 0
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 10
  # Whether to multiply each column with each column and expand features
  multiply_each: False
  # Take square root of features
  square_root: True
  # Apply log transform as scalar
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'median'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: False
  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"


more_than_one_jet:
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter
  lambda: 0
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 10
  # Whether to multiply each column with each column and expand features
  multiply_each: False
  # Take square root of features
  square_root: True
  # Apply log transform as scalar
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'mode'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: False
  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"

# Paths
train_data: "../data/train.csv"
test_data: "../data/test.csv"
# Submissions output_path
output_path: "../results/"
# Visualizations output path
viz_path: "../visualizations/"