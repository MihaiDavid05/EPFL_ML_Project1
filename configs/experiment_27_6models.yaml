# TODO: make this config THE BEST!!!!

# Parameters for each of the models (by jet number)

zero_jet_0:
  # 26123 samples
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter 1e-14
  lambda: 0.00000000000001
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 12
  # Wheather to multiply each column with each column and expand features
  multiply_each: True
  # Take square root of features
  square_root: True
  # Apply log transform as scaler
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'median'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: 'std'
  # Drop correlated features
  drop_corr: True
  # Expand angle features by taking cos and sin
  trig: False

  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"

zero_jet_1:
  # 73790 samples
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter 1e-14
  lambda: 0.00000000000001
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 12
  # Wheather to multiply each column with each column and expand features
  multiply_each: True
  # Take square root of features
  square_root: True
  # Apply log transform as scaler
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'median'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: 'std'
  # Drop correlated features
  drop_corr: True
  # Expand angle features by taking cos and sin
  trig: False

  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"


one_jet_0:
  # 7562 samples
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter 1e-16
  lambda: 0.0000000000000001
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 10
  # Wheather to multiply each column with each column and expand features
  multiply_each: True
  # Take square root of features
  square_root: True
  # Apply log transform as scaler
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'mode'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: False
  # Drop correlated features
  drop_corr: False
  # Expand angle features by taking cos and sin
  trig: False

  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"

one_jet_1:
  # 69982 samples
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter 1e-16
  lambda: 0.0000000000000001
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 10
  # Wheather to multiply each column with each column and expand features
  multiply_each: True
  # Take square root of features
  square_root: True
  # Apply log transform as scaler
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'mode'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: False
  # Drop correlated features
  drop_corr: False
  # Expand angle features by taking cos and sin
  trig: False

  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"

more_than_one_jet_0:
  # 4429 samples
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter 1e-16
  lambda: 0.0000000000000001
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 11
  # Wheather to multiply each column with each column and expand features
  multiply_each: True
  # Take square root of features
  square_root: True
  # Apply log transform as scaler
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'mode'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: False
  # Drop correlated features
  drop_corr: False
  # Expand angle features by taking cos and sin
  trig: False

  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"

more_than_one_jet_1:
  # 68114 samples
  # Model type
  model: ridge
  # step_size
  gamma: null
  # number of steps to run
  max_iters: null
  # regularization parameter 1e-16
  lambda: 0.0000000000000001
  # ratio split
  ratio: null
  # Enable cross validation
  cross_val: True
  # Number of folds for cross-validation
  kfold: 5
  # Whether to build polynomial features or not
  build_poly: True
  # Degrees for polynomial features
  degree: 11
  # Wheather to multiply each column with each column and expand features
  multiply_each: True
  # Take square root of features
  square_root: True
  # Apply log transform as scaler
  log_transform: False
  # Replace -999 values with specified value, this can take 'zero', 'mean', 'median', 'mode' or null
  replace_with: 'mode'
  # Apply only normalization
  only_normalize: False
  # Logistic regression threshold
  reg_threshold: 0.5
  # remove outliers:
  remove_outliers: False
  # Drop correlated features
  drop_corr: False
  # Expand angle features by taking cos and sin
  trig: False

  # Paths
  train_data: "../data/train.csv"
  test_data: "../data/test.csv"
  # Submissions output_path
  output_path: "../results/"
  # Visualizations output path
  viz_path: "../visualizations/"

# Paths
train_data: "../data/train.csv"
test_data: "../data/test.csv"
# Submissions output_path
output_path: "../results/"
# Visualizations output path
viz_path: "../visualizations/"